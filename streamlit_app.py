import streamlit as st
import openai
import os
import base64
import time
import requests
import json
import sys
import hashlib
import hmac

# ğŸ’¡ ì‹œí¬ë¦¿ í‚¤ ì„¤ì •
openai.api_key = st.secrets["OPENAI_API_KEY"]
NAVER_OCR_CLIENT_ID = st.secrets["NAVER_OCR_CLIENT_ID"]
NAVER_OCR_CLIENT_SECRET = st.secrets["NAVER_OCR_CLIENT_SECRET"]

# ğŸ“ í˜ì´ì§€ ì œëª©
st.title("ğŸ“— ë‚˜ì˜ ì•Œãƒ»ê¶ãƒ»ë‚˜ ë…¸íŠ¸")

# ğŸ“Œ ì„¤ëª… ë¬¸êµ¬
st.markdown("""
**ğŸ§ ë…¸íŠ¸ê°€ ìë™ìœ¼ë¡œ ìŒ“ì¸ë‹¤!**

ì˜¤ëŠ˜ ë°°ìš´ ë‚´ìš©ì„ ê¸°ë¡ë§Œ í•´ ì£¼ì„¸ìš”.
ì§ˆë¬¸ ìˆ˜ì¤€ì„ ë†’ì—¬ë“œë¦´ê²Œìš”.
(ë³µìŠµ ë¬¸ì œ ì œê³µì€ ì—…ë°ì´íŠ¸ ì˜ˆì •)

ì´ë¯¸ ì†ê¸€ì”¨ë¡œ ì“´ ë…¸íŠ¸ê°€ ìˆë‹¤ë©´ ì‚¬ì§„ì„ ì°ì–´ ì—…ë¡œë“œí•˜ë©´
ìë™ìœ¼ë¡œ ëŒ€ì‹  ì¨ ë“œë¦´ê²Œìš”.
*"ì´ë¯¸ì§€ ìë™ ì…ë ¥"ìœ¼ë¡œ ì˜ ì¸ì‹ë˜ì§€ ì•Šìœ¼ë©´ ì§ì ‘ ì…ë ¥í•´ ì£¼ì„¸ìš”!*
""")

# âœ¨ ì…ë ¥ ë°©ì‹ ì„ íƒ
mode = st.radio("âœï¸ ì…ë ¥ ë°©ì‹ ì„ íƒ", ["ğŸ–¼ï¸ OCR ìë™ ì…ë ¥", "âŒ¨ï¸ ìˆ˜ë™ ì…ë ¥"], horizontal=True)

ì•Œ, ê¶, ë‚˜ = "", "", ""

# âœ… OCR ì…ë ¥ ì²˜ë¦¬
if mode == "ğŸ–¼ï¸ OCR ìë™ ì…ë ¥":
    uploaded_file = st.file_uploader(
        "ë…¸íŠ¸ ì‚¬ì§„ì„ ì˜¬ë ¤ ì£¼ì„¸ìš”.", type=["png", "jpg", "jpeg"])
    result_text = ""

    # ì‚¬ìš©ì ì„¤ì •
access_key = st.secrets["NAVER_OCR_CLIENT_ID"]
secret_key = st.secrets["NAVER_OCR_CLIENT_SECRET"]

OCR_REQUEST_URL = "https://YOUR_API_GATEWAY_ID.apigw.ntruss.com/custom/v1/XXXXX"  # ë°œê¸‰ë°›ì€ endpoint
OCR_URI = "/custom/v1/XXXXX"

def make_signature():
    timestamp = str(int(time.time() * 1000))
    method = "POST"
    message = method + " " + OCR_URI + "\n" + timestamp + "\n" + access_key
    message = bytes(message, 'UTF-8')
    signingKey = base64.b64encode(hmac.new(bytes(secret_key, 'UTF-8'), message, digestmod=hashlib.sha256).digest())
    return signingKey.decode('utf-8'), timestamp


st.title("ğŸ“— ë‚˜ì˜ ì•Œãƒ»ê¶ãƒ»ë‚˜ ë…¸íŠ¸ - OCR ìë™ ë³€í™˜")

uploaded_file = st.file_uploader("ë…¸íŠ¸ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["png", "jpg", "jpeg"])

if uploaded_file is not None:
    image_data = base64.b64encode(uploaded_file.read()).decode('utf-8')

    payload = {
        "version": "V2",
        "requestId": "sample_id",
        "timestamp": int(time.time() * 1000),
        "images": [{
            "name": "note",
            "format": "jpg",
            "data": image_data
        }]
    }

    signature, timestamp = make_signature()

    headers = {
        "Content-Type": "application/json",
        "x-ncp-apigw-timestamp": timestamp,
        "x-ncp-iam-access-key": access_key,
        "x-ncp-apigw-signature-v2": signature
    }

    response = requests.post(OCR_REQUEST_URL, headers=headers, data=json.dumps(payload))

    if response.status_code == 200:
        st.success("OCR ë¶„ì„ ì™„ë£Œ")
        st.json(response.json())
    else:
        st.error("OCR ë¶„ì„ ì‹¤íŒ¨")
        st.write("ì‘ë‹µ ì½”ë“œ:", response.status_code)
        st.text(response.text)

with st.form("ocr_note_form"):
        ì•Œ = st.text_area("1ï¸âƒ£ ì•Œê²Œ ëœ ì ", value=result_text, key="ocr_ì•Œ")
        ê¶ = st.text_area("2ï¸âƒ£ ê¶ê¸ˆí•œ ì ", key="ocr_ê¶")
        ë‚˜ = st.text_area("3ï¸âƒ£ ë‚˜ì˜ ìƒê°", key="ocr_ë‚˜")
        ocr_submitted = st.form_submit_button("âœï¸ ë¶„ì„í•˜ê¸°")

if ocr_submitted:
    analyze = True

# âœ… ìˆ˜ë™ ì…ë ¥ ì²˜ë¦¬
elif mode == "âŒ¨ï¸ ìˆ˜ë™ ì…ë ¥":
    with st.form("manual_form"):
        ì•Œ = st.text_area("1ï¸âƒ£ ì•Œê²Œ ëœ ì ", key="ìˆ˜ë™_ì•Œ", placeholder="ì˜ˆ: ì§€êµ¬ì˜ ìì „ ë•Œë¬¸ì— ë‚®ê³¼ ë°¤ì´ ìƒê¸´ë‹¤.")
        ê¶ = st.text_area("2ï¸âƒ£ ê¶ê¸ˆí•œ ì ", key="ìˆ˜ë™_ê¶", placeholder="ì˜ˆ: ì§€êµ¬ê°€ ìì „í•˜ì§€ ì•Šìœ¼ë©´ ì–´ë–»ê²Œ ë ê¹Œ?")
        ë‚˜ = st.text_area("3ï¸âƒ£ ë‚˜ì˜ ìƒê°", key="ìˆ˜ë™_ë‚˜", placeholder="ì˜ˆ: ë°¤í•˜ëŠ˜ì˜ ë³„ì´ ìì „ê³¼ ê´€ë ¨ ìˆë‹¤ëŠ” ê±¸ ìƒˆë¡­ê²Œ ì•Œê²Œ ë˜ì—ˆì–´.")
        manual_submitted = st.form_submit_button("âœï¸ ë¶„ì„í•˜ê¸°")

    if manual_submitted:
        analyze = True

# âœ… GPT ë¶„ì„ ë¡œì§ ê³µí†µ ì‹¤í–‰
if "analyze" in locals() and analyze:
    with st.spinner("ì¸ê³µì§€ëŠ¥ì´ ë…¸íŠ¸ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        SYSTEM_PROMPT = """
        ë„ˆëŠ” ì´ˆë“±í•™ìƒì˜ ì§ˆë¬¸ì„ í‰ê°€í•˜ëŠ” ì „ë¬¸ê°€ì•¼.
        í•™ìƒì´ ì…ë ¥í•œ ì§ˆë¬¸ì´ ë¸”ë£¸ì˜ ì¸ì§€ì  ìˆ˜ì¤€ ì¤‘ ì–´ë””ì— í•´ë‹¹í•˜ëŠ”ì§€ë¥¼ íŒë‹¨í•˜ê³ ,
        ê·¸ ì´ìœ ì™€ ì§ˆë¬¸ì„ ë” ê¹Šì´ ìˆëŠ” ìˆ˜ì¤€ìœ¼ë¡œ ë°”ê¿€ ìˆ˜ ìˆëŠ” ì œì•ˆì„ í•´ ì¤˜.

        ë¸”ë£¸ì˜ 6ë‹¨ê³„ëŠ” ë‹¤ìŒê³¼ ê°™ì•„:
        1 ê¸°ì–µí•˜ê¸° (ì‚¬ì‹¤, ìš©ì–´ ë‚˜ì—´)
        2 ì´í•´í•˜ê¸° (ì„¤ëª…, ìš”ì•½)
        3 ì ìš©í•˜ê¸° (ì‹¤ìƒí™œ ì‚¬ë¡€)
        4 ë¶„ì„í•˜ê¸° (ë¹„êµ, ê´€ê³„ íŒŒì•…)
        5 í‰ê°€í•˜ê¸° (íŒë‹¨, ê·¼ê±° ì œì‹œ)
        6 ì°½ì¡°í•˜ê¸° (ìƒˆë¡œìš´ ì§ˆë¬¸ ë§Œë“¤ê¸°, ê°€ì •í•˜ê¸°)

        ë˜í•œ í•™ìƒì´ ì“´ â€˜ì•Œê²Œ ëœ ì â€™ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ 3ê°œë¥¼ ë½‘ê³ ,
â€˜ê¶ê¸ˆí•œ ì â€™ì—ì„œ ì§ˆë¬¸ ì˜ë„ë¥¼ ë¶„ì„í•´ì¤˜. (ì˜ˆ: ì‚¬ì‹¤ í™•ì¸, ì›ì¸ íŒŒì•…, ê°ì • í‘œí˜„ ë“±)
â€˜ë‚˜ì˜ ìƒê°â€™ì—ëŠ” ê°ì •ì´ë‚˜ íƒœë„ê°€ ë“œëŸ¬ë‚˜ ìˆëŠ”ì§€ ì•Œë ¤ì¤˜.

ì•„ë˜ì™€ ê°™ì€ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì •í™•íˆ ì‘ë‹µí•´ ì¤˜.

{
    "keyword": ["í•µì‹¬", "í‚¤ì›Œë“œ", "3ê°œ"],
    "question_intent": "ì§ˆë¬¸ ì˜ë„",
    "attitude_emotion": "ê°ì • ë˜ëŠ” íƒœë„",
    "level": 4,
    "level_name": "ë¶„ì„í•˜ê¸°",
    "rationale": "í•´ë‹¹ ìˆ˜ì¤€ìœ¼ë¡œ íŒë‹¨í•œ ì´ìœ ",
    "improvement": "ë” ë†’ì€ ìˆ˜ì¤€ìœ¼ë¡œ ì§ˆë¬¸ì„ ë°”ê¾¸ëŠ” ë°©ë²•"
            "level": 3,
            "level_name": "ì ìš©í•˜ê¸°",
            "rationale": "ì‹¤ì œ ìƒí™©ì„ ë“¤ì–´ ì„¤ëª…í•˜ë ¤ í–ˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.",
            "improvement": "ì´ ì§ˆë¬¸ì„ ë” ë†’ì€ ìˆ˜ì¤€ìœ¼ë¡œ ë°”ê¾¸ë ¤ë©´, ë¬¸ì œ ìƒí™© ì† ì›ì¸ì´ë‚˜ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ë°”ê¿” ë³´ì„¸ìš”."
}
        """

        prompt = f"""
        ì•„ë˜ëŠ” í•œ ì´ˆë“±í•™ìƒì´ ì“´ ì•Œãƒ»ê¶ãƒ»ë‚˜ í•™ìŠµ ë…¸íŠ¸ì…ë‹ˆë‹¤.

        [ì•Œê²Œ ëœ ì ]  
        {ì•Œ}

        [ê¶ê¸ˆí•œ ì ]  
        {ê¶}

        [ë‚˜ì˜ ìƒê°]  
        {ë‚˜}

        ìœ„ì˜ ë‚´ìš©ì„ ìš”ì•½í•´ì„œ ë‹¤ìŒ í•­ëª©ìœ¼ë¡œ êµ¬ë¶„í•´ì¤˜:
        1. ì•Œê²Œ ëœ ì ì˜ í•µì‹¬ í‚¤ì›Œë“œ 3ê°œ
        2. ê¶ê¸ˆí•œ ì ì˜ ì§ˆë¬¸ ì˜ë„ (ì˜ˆ: ì‚¬ì‹¤ í™•ì¸, ì›ì¸ íŒŒì•…, ê°ì • í‘œí˜„ ë“±)
        3. ë‚˜ì˜ ìƒê°ì—ì„œ ë“œëŸ¬ë‚œ í•™ìƒì˜ íƒœë„ë‚˜ ê°ì •
        """

    try:
            client = openai.OpenAI(api_key=openai.api_key)
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
            )
            result = response.choices[0].message.content
            st.success("âœ… ë¶„ì„ ê²°ê³¼")
            st.markdown(result)

    except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
